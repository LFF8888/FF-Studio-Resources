# ä½¿ç”¨ PyTorch Lightning âš¡ï¸ è¿›è¡Œå›¾åƒåˆ†ç±»

æˆ‘ä»¬å°†ä½¿ç”¨ PyTorch Lightning æ„å»ºä¸€ä¸ªå›¾åƒåˆ†ç±»ç®¡é“ã€‚æˆ‘ä»¬å°†éµå¾ªè¿™ä¸ª [é£æ ¼æŒ‡å—](https://lightning.ai/docs/pytorch/stable/starter/style_guide.html) æ¥æé«˜ä»£ç çš„å¯è¯»æ€§å’Œå¯é‡å¤æ€§ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªå¾ˆé…·çš„è§£é‡Šï¼š[ä½¿ç”¨ PyTorch Lightning è¿›è¡Œå›¾åƒåˆ†ç±»](https://wandb.ai/wandb/wandb-lightning/reports/Image-Classification-using-PyTorch-Lightning--VmlldzoyODk1NzY)ã€‚

## è®¾ç½® PyTorch Lightning å’Œ W&B  

å¯¹äºæœ¬æ•™ç¨‹ï¼Œæˆ‘ä»¬éœ€è¦ PyTorch Lightningï¼ˆè¿™ä¸æ˜¯å¾ˆæ˜æ˜¾å—ï¼ï¼‰å’Œ Weights and Biasesã€‚

```python
!pip install lightning torchvision -q
# å®‰è£… weights and biases
!pip install wandb -qU
```

ä½ éœ€è¦è¿™äº›å¯¼å…¥ã€‚

```python
import lightning.pytorch as pl
# ä½ æœ€å–œæ¬¢çš„æœºå™¨å­¦ä¹ è·Ÿè¸ªå·¥å…·
from lightning.pytorch.loggers import WandbLogger

import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import random_split, DataLoader

from torchmetrics import Accuracy

from torchvision import transforms
from torchvision.datasets import CIFAR10

import wandb
```

ç°åœ¨ä½ éœ€è¦ç™»å½•åˆ°ä½ çš„ wandb è´¦æˆ·ã€‚

```python
wandb.login()
```

## ğŸ”§ DataModule - æˆ‘ä»¬åº”å¾—çš„æ•°æ®ç®¡é“  

DataModules æ˜¯ä¸€ç§å°†æ•°æ®ç›¸å…³çš„é’©å­ä¸ LightningModule è§£è€¦çš„æ–¹å¼ï¼Œä»¥ä¾¿ä½ å¯ä»¥å¼€å‘ä¸æ•°æ®é›†æ— å…³çš„æ¨¡å‹ã€‚  
å®ƒå°†æ•°æ®ç®¡é“ç»„ç»‡æˆä¸€ä¸ªå¯å…±äº«å’Œå¯é‡ç”¨çš„ç±»ã€‚ä¸€ä¸ª datamodule å°è£…äº† PyTorch ä¸­æ•°æ®å¤„ç†çš„äº”ä¸ªæ­¥éª¤ï¼š  
- ä¸‹è½½ / åˆ†è¯ / å¤„ç†ã€‚  
- æ¸…ç†å¹¶ï¼ˆå¯èƒ½ï¼‰ä¿å­˜åˆ°ç£ç›˜ã€‚  
- åŠ è½½åˆ° Dataset ä¸­ã€‚  
- åº”ç”¨è½¬æ¢ï¼ˆæ—‹è½¬ã€åˆ†è¯ç­‰ï¼‰ã€‚  
- åŒ…è£…åˆ° DataLoader ä¸­ã€‚  

äº†è§£æ›´å¤šå…³äº datamodules çš„ä¿¡æ¯ [è¿™é‡Œ](https://lightning.ai/docs/pytorch/stable/data/datamodule.html)ã€‚è®©æˆ‘ä»¬ä¸º Cifar-10 æ•°æ®é›†æ„å»ºä¸€ä¸ª datamoduleã€‚

```python
class CIFAR10DataModule(pl.LightningDataModule):
    def __init__(self, batch_size, data_dir: str = './'):
        super().__init__()
        self.data_dir = data_dir
        self.batch_size = batch_size

        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        self.num_classes = 10

    def prepare_data(self):
        CIFAR10(self.data_dir, train=True, download=True)
        CIFAR10(self.data_dir, train=False, download=True)

    def setup(self, stage=None):
        # ä¸º dataloaders åˆ†é…è®­ç»ƒ/éªŒè¯æ•°æ®é›†
        if stage == 'fit' or stage is None:
            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)
            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])

        # ä¸º dataloader(s) åˆ†é…æµ‹è¯•æ•°æ®é›†
        if stage == 'test' or stage is None:
            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)

    def train_dataloader(self):
        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True)

    def val_dataloader(self):
        return DataLoader(self.cifar_val, batch_size=self.batch_size)

    def test_dataloader(self):
        return DataLoader(self.cifar_test, batch_size=self.batch_size)
```

## ğŸ“± Callbacks  

å›è°ƒæ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç¨‹åºï¼Œå¯ä»¥åœ¨é¡¹ç›®ä¹‹é—´é‡ç”¨ã€‚PyTorch Lightning æä¾›äº†ä¸€äº› [å†…ç½®å›è°ƒ](https://lightning.ai/docs/pytorch/latest/extensions/callbacks.html#built-in-callbacks)ï¼Œè¿™äº›å›è°ƒç»å¸¸è¢«ä½¿ç”¨ã€‚  
äº†è§£æ›´å¤šå…³äº PyTorch Lightning ä¸­çš„å›è°ƒ [è¿™é‡Œ](https://lightning.ai/docs/pytorch/latest/extensions/callbacks.html)ã€‚

### å†…ç½®å›è°ƒ  

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Early Stopping](https://lightning.ai/docs/pytorch/latest/api/lightning.pytorch.callbacks.EarlyStopping.html#lightning.callbacks.EarlyStopping) å’Œ [Model Checkpoint](https://lightning.ai/docs/pytorch/latest/api/lightning.pytorch.callbacks.ModelCheckpoint.html#pytorch_lightning.callbacks.ModelCheckpoint) å†…ç½®å›è°ƒã€‚å®ƒä»¬å¯ä»¥ä¼ é€’ç»™ `Trainer`ã€‚

### è‡ªå®šä¹‰å›è°ƒ  

å¦‚æœä½ ç†Ÿæ‚‰è‡ªå®šä¹‰ Keras å›è°ƒï¼Œé‚£ä¹ˆåœ¨ PyTorch ç®¡é“ä¸­å®ç°ç›¸åŒåŠŸèƒ½çš„èƒ½åŠ›åªæ˜¯é”¦ä¸Šæ·»èŠ±ã€‚  
ç”±äºæˆ‘ä»¬æ­£åœ¨è¿›è¡Œå›¾åƒåˆ†ç±»ï¼Œèƒ½å¤Ÿå¯è§†åŒ–æ¨¡å‹å¯¹ä¸€äº›æ ·æœ¬å›¾åƒçš„é¢„æµ‹å¯èƒ½å¾ˆæœ‰å¸®åŠ©ã€‚è¿™ç§å½¢å¼çš„å›è°ƒå¯ä»¥å¸®åŠ©åœ¨æ—©æœŸé˜¶æ®µè°ƒè¯•æ¨¡å‹ã€‚

```python
class ImagePredictionLogger(pl.callbacks.Callback):
    def __init__(self, val_samples, num_samples=32):
        super().__init__()
        self.num_samples = num_samples
        self.val_imgs, self.val_labels = val_samples

    def on_validation_epoch_end(self, trainer, pl_module):
        # å°†å¼ é‡å¸¦åˆ° CPU
        val_imgs = self.val_imgs.to(device=pl_module.device)
        val_labels = self.val_labels.to(device=pl_module.device)
        # è·å–æ¨¡å‹é¢„æµ‹
        logits = pl_module(val_imgs)
        preds = torch.argmax(logits, -1)
        # å°†å›¾åƒè®°å½•ä¸º wandb Image
        trainer.logger.experiment.log({
            "examples":[wandb.Image(x, caption=f"Pred:{pred}, Label:{y}")
                           for x, pred, y in zip(val_imgs[:self.num_samples],
                                                 preds[:self.num_samples],
                                                 val_labels[:self.num_samples])]
            })
```

## ğŸº LightningModule - å®šä¹‰ç³»ç»Ÿ  

LightningModule å®šä¹‰äº†ä¸€ä¸ªç³»ç»Ÿï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ¨¡å‹ã€‚åœ¨è¿™é‡Œï¼Œç³»ç»Ÿå°†æ‰€æœ‰ç ”ç©¶ä»£ç åˆ†ç»„åˆ°ä¸€ä¸ªç±»ä¸­ï¼Œä½¿å…¶è‡ªåŒ…å«ã€‚`LightningModule` å°†ä½ çš„ PyTorch ä»£ç ç»„ç»‡æˆ 5 ä¸ªéƒ¨åˆ†ï¼š  
- è®¡ç®— (`__init__`)ã€‚  
- è®­ç»ƒå¾ªç¯ (`training_step`)  
- éªŒè¯å¾ªç¯ (`validation_step`)  
- æµ‹è¯•å¾ªç¯ (`test_step`)  
- ä¼˜åŒ–å™¨ (`configure_optimizers`)  

å› æ­¤ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªä¸æ•°æ®é›†æ— å…³çš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾å…±äº«ã€‚è®©æˆ‘ä»¬ä¸º Cifar-10 åˆ†ç±»æ„å»ºä¸€ä¸ªç³»ç»Ÿã€‚

```python
class LitModel(pl.LightningModule):
    def __init__(self, input_shape, num_classes, learning_rate=2e-4):
        super().__init__()

        # è®°å½•è¶…å‚æ•°
        self.save_hyperparameters()
        self.learning_rate = learning_rate

        self.conv1 = nn.Conv2d(3, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 32, 3, 1)
        self.conv3 = nn.Conv2d(32, 64, 3, 1)
        self.conv4 = nn.Conv2d(64, 64, 3, 1)

        self.pool1 = torch.nn.MaxPool2d(2)
        self.pool2 = torch.nn.MaxPool2d(2)

        n_sizes = self._get_conv_output(input_shape)

        self.fc1 = nn.Linear(n_sizes, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, num_classes)

        self.accuracy = Accuracy(task="multiclass", num_classes=num_classes)

    # è¿”å›ä»å·ç§¯å—è¿›å…¥çº¿æ€§å±‚çš„è¾“å‡ºå¼ é‡çš„å¤§å°ã€‚
    def _get_conv_output(self, shape):
        batch_size = 1
        input = torch.autograd.Variable(torch.rand(batch_size, *shape))

        output_feat = self._forward_features(input)
        n_size = output_feat.data.view(batch_size, -1).size(1)
        return n_size

    # è¿”å›å·ç§¯å—çš„ç‰¹å¾å¼ é‡
    def _forward_features(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = self.pool2(F.relu(self.conv4(x)))
        return x

    # å°†åœ¨æ¨ç†æœŸé—´ä½¿ç”¨
    def forward(self, x):
       x = self._forward_features(x)
       x = x.view(x.size(0), -1)
       x = F.relu(self.fc1(x))
       x = F.relu(self.fc2(x))
       x = F.log_softmax(self.fc3(x), dim=1)

       return x

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)

        # è®­ç»ƒæŒ‡æ ‡
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)
        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)

        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)

        # éªŒè¯æŒ‡æ ‡
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        return loss

    def test_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)

        # éªŒè¯æŒ‡æ ‡
        preds = torch.argmax(logits, dim=1)
        acc = self.accuracy(preds, y)
        self.log('test_loss', loss, prog_bar=True)
        self.log('test_acc', acc, prog_bar=True)
        return loss

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        return optimizer
```

## ğŸš‹ è®­ç»ƒå’Œè¯„ä¼°  

ç°åœ¨æˆ‘ä»¬å·²ç»ä½¿ç”¨ `DataModule` ç»„ç»‡äº†æ•°æ®ç®¡é“ï¼Œå¹¶ä½¿ç”¨ `LightningModule` ç»„ç»‡äº†æ¨¡å‹æ¶æ„å’Œè®­ç»ƒå¾ªç¯ï¼ŒPyTorch Lightning `Trainer` ä¸ºæˆ‘ä»¬è‡ªåŠ¨åŒ–äº†å…¶ä»–æ‰€æœ‰å†…å®¹ã€‚  

Trainer è‡ªåŠ¨åŒ–äº†ä»¥ä¸‹å†…å®¹ï¼š  
- Epoch å’Œ batch è¿­ä»£  
- è°ƒç”¨ `optimizer.step()`ã€`backward`ã€`zero_grad()`  
- è°ƒç”¨ `.eval()`ï¼Œå¯ç”¨/ç¦ç”¨æ¢¯åº¦  
- ä¿å­˜å’ŒåŠ è½½æƒé‡  
- Weights and Biases æ—¥å¿—è®°å½•  
- å¤š GPU è®­ç»ƒæ”¯æŒ  
- TPU æ”¯æŒ  
- 16 ä½è®­ç»ƒæ”¯æŒ  

```python
dm = CIFAR10DataModule(batch_size=32)
# è¦è®¿é—® x_dataloaderï¼Œæˆ‘ä»¬éœ€è¦è°ƒç”¨ prepare_data å’Œ setupã€‚
dm.prepare_data()
dm.setup()

# è‡ªå®šä¹‰ ImagePredictionLogger å›è°ƒæ‰€éœ€çš„æ ·æœ¬ï¼Œç”¨äºè®°å½•å›¾åƒé¢„æµ‹ã€‚
val_samples = next(iter(dm.val_dataloader()))
val_imgs, val_labels = val_samples[0], val_samples[1]
val_imgs.shape, val_labels.shape
```

```python
model = LitModel((3, 32, 32), dm.num_classes)

# åˆå§‹åŒ– wandb logger
wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')

# åˆå§‹åŒ– Callbacks
early_stop_callback = pl.callbacks.EarlyStopping(monitor="val_loss")
checkpoint_callback = pl.callbacks.ModelCheckpoint()

# åˆå§‹åŒ–ä¸€ä¸ª trainer
trainer = pl.Trainer(max_epochs=2,
                     logger=wandb_logger,
                     callbacks=[early_stop_callback,
                                ImagePredictionLogger(val_samples),
                                checkpoint_callback],
                     )

# è®­ç»ƒæ¨¡å‹ âš¡ğŸš…âš¡
trainer.fit(model, dm)

# åœ¨ä¿ç•™çš„æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ âš¡âš¡
trainer.test(dataloaders=dm.test_dataloader())

# å…³é—­ wandb run
wandb.finish()
```

## æœ€ç»ˆæƒ³æ³•  

æˆ‘æ¥è‡ª TensorFlow/Keras ç”Ÿæ€ç³»ç»Ÿï¼Œå‘ç° PyTorch è™½ç„¶æ˜¯ä¸€ä¸ªä¼˜é›…çš„æ¡†æ¶ï¼Œä½†æœ‰ç‚¹è®©äººä¸çŸ¥æ‰€æªã€‚è¿™åªæ˜¯æˆ‘çš„ä¸ªäººç»éªŒã€‚åœ¨æ¢ç´¢ PyTorch Lightning æ—¶ï¼Œæˆ‘æ„è¯†åˆ°å‡ ä¹æ‰€æœ‰è®©æˆ‘è¿œç¦» PyTorch çš„åŸå› éƒ½å¾—åˆ°äº†è§£å†³ã€‚ä»¥ä¸‹æ˜¯æˆ‘å…´å¥‹çš„å¿«é€Ÿæ€»ç»“ï¼š  
- è¿‡å»ï¼šä¼ ç»Ÿçš„ PyTorch æ¨¡å‹å®šä¹‰é€šå¸¸åˆ†æ•£åœ¨å„ä¸ªåœ°æ–¹ã€‚æ¨¡å‹åœ¨æŸä¸ª `model.py` è„šæœ¬ä¸­ï¼Œè®­ç»ƒå¾ªç¯åœ¨ `train.py` æ–‡ä»¶ä¸­ã€‚éœ€è¦æ¥å›æŸ¥çœ‹æ‰èƒ½ç†è§£ç®¡é“ã€‚  
- ç°åœ¨ï¼š`LightningModule` ä½œä¸ºä¸€ä¸ªç³»ç»Ÿï¼Œæ¨¡å‹å®šä¹‰ä¸ `training_step`ã€`validation_step` ç­‰ä¸€èµ·å®šä¹‰ã€‚ç°åœ¨å®ƒæ˜¯æ¨¡å—åŒ–çš„ä¸”å¯å…±äº«çš„ã€‚  
- è¿‡å»ï¼šTensorFlow/Keras æœ€æ£’çš„éƒ¨åˆ†æ˜¯è¾“å…¥æ•°æ®ç®¡é“ã€‚ä»–ä»¬çš„æ•°æ®é›†ç›®å½•ä¸°å¯Œä¸”ä¸æ–­å¢é•¿ã€‚PyTorch çš„æ•°æ®ç®¡é“æ›¾ç»æ˜¯æœ€å¤§çš„ç—›ç‚¹ã€‚åœ¨æ™®é€šçš„ PyTorch ä»£ç ä¸­ï¼Œæ•°æ®ä¸‹è½½/æ¸…ç†/å‡†å¤‡é€šå¸¸åˆ†æ•£åœ¨è®¸å¤šæ–‡ä»¶ä¸­ã€‚  
- ç°åœ¨ï¼šDataModule å°†æ•°æ®ç®¡é“ç»„ç»‡æˆä¸€ä¸ªå¯å…±äº«å’Œå¯é‡ç”¨çš„ç±»ã€‚å®ƒåªæ˜¯ `train_dataloader`ã€`val_dataloader`(s)ã€`test_dataloader`(s) ä»¥åŠåŒ¹é…çš„è½¬æ¢å’Œæ•°æ®å¤„ç†/ä¸‹è½½æ­¥éª¤çš„é›†åˆã€‚  
- è¿‡å»ï¼šä½¿ç”¨ Kerasï¼Œå¯ä»¥è°ƒç”¨ `model.fit` æ¥è®­ç»ƒæ¨¡å‹ï¼Œè°ƒç”¨ `model.predict` æ¥è¿è¡Œæ¨ç†ã€‚`model.evaluate` æä¾›äº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„æµ‹è¯•æ•°æ®è¯„ä¼°ã€‚è¿™åœ¨ PyTorch ä¸­ä¸æ˜¯è¿™æ ·ã€‚é€šå¸¸ä¼šæ‰¾åˆ°å•ç‹¬çš„ `train.py` å’Œ `test.py` æ–‡ä»¶ã€‚  
- ç°åœ¨ï¼šæœ‰äº† `LightningModule`ï¼Œ`Trainer` è‡ªåŠ¨åŒ–äº†ä¸€åˆ‡ã€‚åªéœ€è°ƒç”¨ `trainer.fit` å’Œ `trainer.test` æ¥è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚  
- è¿‡å»ï¼šTensorFlow å–œæ¬¢ TPUï¼ŒPyTorch...å—¯ï¼  
- ç°åœ¨ï¼šä½¿ç”¨ PyTorch Lightningï¼Œå¯ä»¥è½»æ¾åœ°åœ¨å¤šä¸ª GPU ä¸Šè®­ç»ƒç›¸åŒçš„æ¨¡å‹ï¼Œç”šè‡³åœ¨ TPU ä¸Šã€‚å“‡ï¼  
- è¿‡å»ï¼šæˆ‘æ˜¯å›è°ƒçš„å¿ å®ç²‰ä¸ï¼Œæ›´å–œæ¬¢ç¼–å†™è‡ªå®šä¹‰å›è°ƒã€‚åƒ Early Stopping è¿™æ ·ç®€å•çš„äº‹æƒ…æ›¾ç»æ˜¯ä¼ ç»Ÿ PyTorch çš„è®¨è®ºç‚¹ã€‚  
- ç°åœ¨ï¼šä½¿ç”¨ PyTorch Lightningï¼Œä½¿ç”¨ Early Stopping å’Œ Model Checkpointing æ˜¯å°èœä¸€ç¢Ÿã€‚æˆ‘ç”šè‡³å¯ä»¥ç¼–å†™è‡ªå®šä¹‰å›è°ƒã€‚

## ğŸ¨ ç»“è®ºå’Œèµ„æº  

æˆ‘å¸Œæœ›ä½ è§‰å¾—è¿™ä»½æŠ¥å‘Šæœ‰å¸®åŠ©ã€‚æˆ‘é¼“åŠ±ä½ ç©ä¸€ä¸‹ä»£ç ï¼Œå¹¶ä½¿ç”¨ä½ é€‰æ‹©çš„æ•°æ®é›†è®­ç»ƒä¸€ä¸ªå›¾åƒåˆ†ç±»å™¨ã€‚  

ä»¥ä¸‹æ˜¯ä¸€äº›å­¦ä¹ æ›´å¤šå…³äº PyTorch Lightning çš„èµ„æºï¼š  
- [é€æ­¥æ¼”ç»ƒ](https://lightning.ai/docs/pytorch/latest/starter/introduction.html) - è¿™æ˜¯å®˜æ–¹æ•™ç¨‹ä¹‹ä¸€ã€‚ä»–ä»¬çš„æ–‡æ¡£å†™å¾—éå¸¸å¥½ï¼Œæˆ‘å¼ºçƒˆæ¨èå®ƒä½œä¸ºå­¦ä¹ èµ„æºã€‚  
- [ä½¿ç”¨ PyTorch Lightning ä¸ Weights & Biases](https://wandb.me/lightning) - è¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿ colabï¼Œä½ å¯ä»¥é€šè¿‡å®ƒå­¦ä¹ å¦‚ä½•ä½¿ç”¨ W&B ä¸ PyTorch Lightningã€‚