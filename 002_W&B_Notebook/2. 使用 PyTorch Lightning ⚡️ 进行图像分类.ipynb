{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3DlI04nJWBJ"
      },
      "source": [
        "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<!--- @wandbcode{pytorch-lightning-image-classification-colab} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvCPHSS5JWBJ"
      },
      "source": [
        "\n",
        "# ä½¿ç”¨ PyTorch Lightning âš¡ï¸ è¿›è¡Œå›¾åƒåˆ†ç±»\n",
        "\n",
        "æˆ‘ä»¬å°†ä½¿ç”¨ PyTorch Lightning æ„å»ºä¸€ä¸ªå›¾åƒåˆ†ç±»ç®¡é“ã€‚æˆ‘ä»¬å°†éµå¾ªè¿™ä¸ª [é£æ ¼æŒ‡å—](https://lightning.ai/docs/pytorch/stable/starter/style_guide.html) æ¥æé«˜ä»£ç çš„å¯è¯»æ€§å’Œå¯é‡å¤æ€§ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªå¾ˆé…·çš„è§£é‡Šï¼š[ä½¿ç”¨ PyTorch Lightning è¿›è¡Œå›¾åƒåˆ†ç±»](https://wandb.ai/wandb/wandb-lightning/reports/Image-Classification-using-PyTorch-Lightning--VmlldzoyODk1NzY)ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vzanw34JWBK"
      },
      "source": [
        "## è®¾ç½® PyTorch Lightning å’Œ W&B\n",
        "\n",
        "å¯¹äºæœ¬æ•™ç¨‹ï¼Œæˆ‘ä»¬éœ€è¦ PyTorch Lightningï¼ˆè¿™ä¸æ˜¯å¾ˆæ˜æ˜¾å—ï¼ï¼‰å’Œ Weights and Biasesã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3GJHc17JWBK"
      },
      "outputs": [],
      "source": [
        "!pip install lightning torchvision -q\n",
        "# å®‰è£… weights and biases\n",
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4esw50JZJWBK"
      },
      "source": [
        "ä½ éœ€è¦è¿™äº›å¯¼å…¥ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GG5OLoFJWBL"
      },
      "outputs": [],
      "source": [
        "import lightning.pytorch as pl\n",
        "# ä½ æœ€å–œæ¬¢çš„æœºå™¨å­¦ä¹ è·Ÿè¸ªå·¥å…·\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOII1Ii6JWBL"
      },
      "source": [
        "ç°åœ¨ä½ éœ€è¦ç™»å½•åˆ°ä½ çš„ wandb è´¦æˆ·ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UenW82qJWBL"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oXtqLoFJWBM"
      },
      "source": [
        "## ğŸ”§ DataModule - æˆ‘ä»¬åº”å¾—çš„æ•°æ®ç®¡é“\n",
        "\n",
        "DataModules æ˜¯ä¸€ç§å°†æ•°æ®ç›¸å…³çš„é’©å­ä¸ LightningModule è§£è€¦çš„æ–¹å¼ï¼Œä»¥ä¾¿ä½ å¯ä»¥å¼€å‘ä¸æ•°æ®é›†æ— å…³çš„æ¨¡å‹ã€‚\n",
        "\n",
        "å®ƒå°†æ•°æ®ç®¡é“ç»„ç»‡æˆä¸€ä¸ªå¯å…±äº«å’Œå¯é‡ç”¨çš„ç±»ã€‚ä¸€ä¸ª datamodule å°è£…äº† PyTorch ä¸­æ•°æ®å¤„ç†çš„äº”ä¸ªæ­¥éª¤ï¼š\n",
        "- ä¸‹è½½ / åˆ†è¯ / å¤„ç†ã€‚\n",
        "- æ¸…ç†å¹¶ï¼ˆå¯èƒ½ï¼‰ä¿å­˜åˆ°ç£ç›˜ã€‚\n",
        "- åŠ è½½åˆ° Dataset ä¸­ã€‚\n",
        "- åº”ç”¨è½¬æ¢ï¼ˆæ—‹è½¬ã€åˆ†è¯ç­‰ï¼‰ã€‚\n",
        "- åŒ…è£…åˆ° DataLoader ä¸­ã€‚\n",
        "\n",
        "äº†è§£æ›´å¤šå…³äº datamodules çš„ä¿¡æ¯ [è¿™é‡Œ](https://lightning.ai/docs/pytorch/stable/data/datamodule.html)ã€‚è®©æˆ‘ä»¬ä¸º Cifar-10 æ•°æ®é›†æ„å»ºä¸€ä¸ª datamoduleã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s-ndiweJWBM"
      },
      "outputs": [],
      "source": [
        "class CIFAR10DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size, data_dir: str = './'):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        self.num_classes = 10\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # ä¸‹è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†\n",
        "        CIFAR10(self.data_dir, train=True, download=True)\n",
        "        CIFAR10(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # ä¸º dataloaders åˆ†é…è®­ç»ƒ/éªŒè¯æ•°æ®é›†\n",
        "        if stage == 'fit' or stage is None:\n",
        "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
        "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
        "\n",
        "        # ä¸º dataloader(s) åˆ†é…æµ‹è¯•æ•°æ®é›†\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # è¿”å›è®­ç»ƒæ•°æ®çš„ DataLoader\n",
        "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # è¿”å›éªŒè¯æ•°æ®çš„ DataLoader\n",
        "        return DataLoader(self.cifar_val, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        # è¿”å›æµ‹è¯•æ•°æ®çš„ DataLoader\n",
        "        return DataLoader(self.cifar_test, batch_size=self.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3V1qveUJWBM"
      },
      "source": [
        "## ğŸ“± Callbacks\n",
        "\n",
        "å›è°ƒæ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç¨‹åºï¼Œå¯ä»¥åœ¨é¡¹ç›®ä¹‹é—´é‡ç”¨ã€‚PyTorch Lightning æä¾›äº†ä¸€äº› [å†…ç½®å›è°ƒ](https://lightning.ai/docs/pytorch/latest/extensions/callbacks.html#built-in-callbacks)ï¼Œè¿™äº›å›è°ƒç»å¸¸è¢«ä½¿ç”¨ã€‚\n",
        "äº†è§£æ›´å¤šå…³äº PyTorch Lightning ä¸­çš„å›è°ƒ [è¿™é‡Œ](https://lightning.ai/docs/pytorch/latest/extensions/callbacks.html)ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVoppAyIJWBM"
      },
      "source": [
        "### å†…ç½®å›è°ƒ\n",
        "\n",
        "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Early Stopping](https://lightning.ai/docs/pytorch/latest/api/lightning.pytorch.callbacks.EarlyStopping.html#lightning.callbacks.EarlyStopping) å’Œ [Model Checkpoint](https://lightning.ai/docs/pytorch/latest/api/lightning.pytorch.callbacks.ModelCheckpoint.html#pytorch_lightning.callbacks.ModelCheckpoint) å†…ç½®å›è°ƒã€‚å®ƒä»¬å¯ä»¥ä¼ é€’ç»™ `Trainer`ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLe2rpXfJWBM"
      },
      "source": [
        "### è‡ªå®šä¹‰å›è°ƒ\n",
        "å¦‚æœä½ ç†Ÿæ‚‰è‡ªå®šä¹‰ Keras å›è°ƒï¼Œé‚£ä¹ˆåœ¨ PyTorch ç®¡é“ä¸­å®ç°ç›¸åŒåŠŸèƒ½çš„èƒ½åŠ›åªæ˜¯é”¦ä¸Šæ·»èŠ±ã€‚\n",
        "\n",
        "ç”±äºæˆ‘ä»¬æ­£åœ¨è¿›è¡Œå›¾åƒåˆ†ç±»ï¼Œèƒ½å¤Ÿå¯è§†åŒ–æ¨¡å‹å¯¹ä¸€äº›æ ·æœ¬å›¾åƒçš„é¢„æµ‹å¯èƒ½å¾ˆæœ‰å¸®åŠ©ã€‚è¿™ç§å½¢å¼çš„å›è°ƒå¯ä»¥å¸®åŠ©åœ¨æ—©æœŸé˜¶æ®µè°ƒè¯•æ¨¡å‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLarmSrMJWBM"
      },
      "outputs": [],
      "source": [
        "class ImagePredictionLogger(pl.callbacks.Callback):\n",
        "    def __init__(self, val_samples, num_samples=32):\n",
        "        super().__init__()\n",
        "        self.num_samples = num_samples\n",
        "        self.val_imgs, self.val_labels = val_samples\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        # å°†å¼ é‡å¸¦åˆ° CPU\n",
        "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
        "        val_labels = self.val_labels.to(device=pl_module.device)\n",
        "        # è·å–æ¨¡å‹é¢„æµ‹\n",
        "        logits = pl_module(val_imgs)\n",
        "        preds = torch.argmax(logits, -1)\n",
        "        # å°†å›¾åƒè®°å½•ä¸º wandb Image\n",
        "        trainer.logger.experiment.log({\n",
        "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\")\n",
        "                           for x, pred, y in zip(val_imgs[:self.num_samples],\n",
        "                                                 preds[:self.num_samples],\n",
        "                                                 val_labels[:self.num_samples])]\n",
        "            })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggjYFSpvJWBM"
      },
      "source": [
        "## ğŸº LightningModule - å®šä¹‰ç³»ç»Ÿ\n",
        "\n",
        "LightningModule å®šä¹‰äº†ä¸€ä¸ªç³»ç»Ÿï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ¨¡å‹ã€‚åœ¨è¿™é‡Œï¼Œç³»ç»Ÿå°†æ‰€æœ‰ç ”ç©¶ä»£ç åˆ†ç»„åˆ°ä¸€ä¸ªç±»ä¸­ï¼Œä½¿å…¶è‡ªåŒ…å«ã€‚`LightningModule` å°†ä½ çš„ PyTorch ä»£ç ç»„ç»‡æˆ 5 ä¸ªéƒ¨åˆ†ï¼š\n",
        "- è®¡ç®— (`__init__`)ã€‚\n",
        "- è®­ç»ƒå¾ªç¯ (`training_step`)\n",
        "- éªŒè¯å¾ªç¯ (`validation_step`)\n",
        "- æµ‹è¯•å¾ªç¯ (`test_step`)\n",
        "- ä¼˜åŒ–å™¨ (`configure_optimizers`)\n",
        "\n",
        "å› æ­¤ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªä¸æ•°æ®é›†æ— å…³çš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾å…±äº«ã€‚è®©æˆ‘ä»¬ä¸º Cifar-10 åˆ†ç±»æ„å»ºä¸€ä¸ªç³»ç»Ÿã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q4ybw7IJWBN"
      },
      "outputs": [],
      "source": [
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self, input_shape, num_classes, learning_rate=2e-4):\n",
        "        super().__init__()\n",
        "\n",
        "        # è®°å½•è¶…å‚æ•°\n",
        "        self.save_hyperparameters()\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, 1)\n",
        "\n",
        "        self.pool1 = torch.nn.MaxPool2d(2)\n",
        "        self.pool2 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        n_sizes = self._get_conv_output(input_shape)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_sizes, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    # è¿”å›ä»å·ç§¯å—è¿›å…¥çº¿æ€§å±‚çš„è¾“å‡ºå¼ é‡çš„å¤§å°ã€‚\n",
        "    def _get_conv_output(self, shape):\n",
        "        batch_size = 1\n",
        "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "\n",
        "        output_feat = self._forward_features(input)\n",
        "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "        return n_size\n",
        "\n",
        "    # è¿”å›å·ç§¯å—çš„ç‰¹å¾å¼ é‡\n",
        "    def _forward_features(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool2(F.relu(self.conv4(x)))\n",
        "        return x\n",
        "\n",
        "    # å°†åœ¨æ¨ç†æœŸé—´ä½¿ç”¨\n",
        "    def forward(self, x):\n",
        "       x = self._forward_features(x)\n",
        "       x = x.view(x.size(0), -1)\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = F.log_softmax(self.fc3(x), dim=1)\n",
        "\n",
        "       return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        # è®­ç»ƒæŒ‡æ ‡\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = self.accuracy(preds, y)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        # éªŒè¯æŒ‡æ ‡\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = self.accuracy(preds, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.nll_loss(logits, y)\n",
        "\n",
        "        # éªŒè¯æŒ‡æ ‡\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = self.accuracy(preds, y)\n",
        "        self.log('test_loss', loss, prog_bar=True)\n",
        "        self.log('test_acc', acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # é…ç½®ä¼˜åŒ–å™¨\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXBrp-mrJWBN"
      },
      "source": [
        "## ğŸš‹ è®­ç»ƒå’Œè¯„ä¼°\n",
        "\n",
        "ç°åœ¨æˆ‘ä»¬å·²ç»ä½¿ç”¨ `DataModule` ç»„ç»‡äº†æ•°æ®ç®¡é“ï¼Œå¹¶ä½¿ç”¨ `LightningModule` ç»„ç»‡äº†æ¨¡å‹æ¶æ„å’Œè®­ç»ƒå¾ªç¯ï¼ŒPyTorch Lightning `Trainer` ä¸ºæˆ‘ä»¬è‡ªåŠ¨åŒ–äº†å…¶ä»–æ‰€æœ‰å†…å®¹ã€‚\n",
        "\n",
        "Trainer è‡ªåŠ¨åŒ–äº†ä»¥ä¸‹å†…å®¹ï¼š\n",
        "- Epoch å’Œ batch è¿­ä»£\n",
        "- è°ƒç”¨ `optimizer.step()`ã€`backward`ã€`zero_grad()`\n",
        "- è°ƒç”¨ `.eval()`ï¼Œå¯ç”¨/ç¦ç”¨æ¢¯åº¦\n",
        "- ä¿å­˜å’ŒåŠ è½½æƒé‡\n",
        "- Weights and Biases æ—¥å¿—è®°å½•\n",
        "- å¤š GPU è®­ç»ƒæ”¯æŒ\n",
        "- TPU æ”¯æŒ\n",
        "- 16 ä½è®­ç»ƒæ”¯æŒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xufWXyXnJWBN"
      },
      "outputs": [],
      "source": [
        "dm = CIFAR10DataModule(batch_size=32)\n",
        "# è¦è®¿é—® x_dataloaderï¼Œæˆ‘ä»¬éœ€è¦è°ƒç”¨ prepare_data å’Œ setupã€‚\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "\n",
        "# è‡ªå®šä¹‰ ImagePredictionLogger å›è°ƒæ‰€éœ€çš„æ ·æœ¬ï¼Œç”¨äºè®°å½•å›¾åƒé¢„æµ‹ã€‚\n",
        "val_samples = next(iter(dm.val_dataloader()))\n",
        "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
        "val_imgs.shape, val_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJr3lFajJWBN"
      },
      "outputs": [],
      "source": [
        "model = LitModel((3, 32, 32), dm.num_classes)\n",
        "\n",
        "# åˆå§‹åŒ– wandb logger\n",
        "wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')\n",
        "\n",
        "# åˆå§‹åŒ– Callbacks\n",
        "early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\")\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint()\n",
        "\n",
        "# åˆå§‹åŒ–ä¸€ä¸ª trainer\n",
        "trainer = pl.Trainer(max_epochs=2,\n",
        "                     logger=wandb_logger,\n",
        "                     callbacks=[early_stop_callback,\n",
        "                                ImagePredictionLogger(val_samples),\n",
        "                                checkpoint_callback],\n",
        "                     )\n",
        "\n",
        "# è®­ç»ƒæ¨¡å‹ âš¡ğŸš…âš¡\n",
        "trainer.fit(model, dm)\n",
        "\n",
        "# åœ¨ä¿ç•™çš„æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ âš¡âš¡\n",
        "trainer.test(dataloaders=dm.test_dataloader())\n",
        "\n",
        "# å…³é—­ wandb run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGjjRwYqJWBN"
      },
      "source": [
        "## æœ€ç»ˆæƒ³æ³•\n",
        "æˆ‘æ¥è‡ª TensorFlow/Keras ç”Ÿæ€ç³»ç»Ÿï¼Œå‘ç° PyTorch è™½ç„¶æ˜¯ä¸€ä¸ªä¼˜é›…çš„æ¡†æ¶ï¼Œä½†æœ‰ç‚¹è®©äººä¸çŸ¥æ‰€æªã€‚è¿™åªæ˜¯æˆ‘çš„ä¸ªäººç»éªŒã€‚åœ¨æ¢ç´¢ PyTorch Lightning æ—¶ï¼Œæˆ‘æ„è¯†åˆ°å‡ ä¹æ‰€æœ‰è®©æˆ‘è¿œç¦» PyTorch çš„åŸå› éƒ½å¾—åˆ°äº†è§£å†³ã€‚ä»¥ä¸‹æ˜¯æˆ‘å…´å¥‹çš„å¿«é€Ÿæ€»ç»“ï¼š\n",
        "- è¿‡å»ï¼šä¼ ç»Ÿçš„ PyTorch æ¨¡å‹å®šä¹‰é€šå¸¸åˆ†æ•£åœ¨å„ä¸ªåœ°æ–¹ã€‚æ¨¡å‹åœ¨æŸä¸ª `model.py` è„šæœ¬ä¸­ï¼Œè®­ç»ƒå¾ªç¯åœ¨ `train.py` æ–‡ä»¶ä¸­ã€‚éœ€è¦æ¥å›æŸ¥çœ‹æ‰èƒ½ç†è§£ç®¡é“ã€‚\n",
        "- ç°åœ¨ï¼š`LightningModule` ä½œä¸ºä¸€ä¸ªç³»ç»Ÿï¼Œæ¨¡å‹å®šä¹‰ä¸ `training_step`ã€`validation_step` ç­‰ä¸€èµ·å®šä¹‰ã€‚ç°åœ¨å®ƒæ˜¯æ¨¡å—åŒ–çš„ä¸”å¯å…±äº«çš„ã€‚\n",
        "- è¿‡å»ï¼šTensorFlow/Keras æœ€æ£’çš„éƒ¨åˆ†æ˜¯è¾“å…¥æ•°æ®ç®¡é“ã€‚ä»–ä»¬çš„æ•°æ®é›†ç›®å½•ä¸°å¯Œä¸”ä¸æ–­å¢é•¿ã€‚PyTorch çš„æ•°æ®ç®¡é“æ›¾ç»æ˜¯æœ€å¤§çš„ç—›ç‚¹ã€‚åœ¨æ™®é€šçš„ PyTorch ä»£ç ä¸­ï¼Œæ•°æ®ä¸‹è½½/æ¸…ç†/å‡†å¤‡é€šå¸¸åˆ†æ•£åœ¨è®¸å¤šæ–‡ä»¶ä¸­ã€‚\n",
        "- ç°åœ¨ï¼šDataModule å°†æ•°æ®ç®¡é“ç»„ç»‡æˆä¸€ä¸ªå¯å…±äº«å’Œå¯é‡ç”¨çš„ç±»ã€‚å®ƒåªæ˜¯ `train_dataloader`ã€`val_dataloader`(s)ã€`test_dataloader`(s) ä»¥åŠåŒ¹é…çš„è½¬æ¢å’Œæ•°æ®å¤„ç†/ä¸‹è½½æ­¥éª¤çš„é›†åˆã€‚\n",
        "- è¿‡å»ï¼šä½¿ç”¨ Kerasï¼Œå¯ä»¥è°ƒç”¨ `model.fit` æ¥è®­ç»ƒæ¨¡å‹ï¼Œè°ƒç”¨ `model.predict` æ¥è¿è¡Œæ¨ç†ã€‚`model.evaluate` æä¾›äº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„æµ‹è¯•æ•°æ®è¯„ä¼°ã€‚è¿™åœ¨ PyTorch ä¸­ä¸æ˜¯è¿™æ ·ã€‚é€šå¸¸ä¼šæ‰¾åˆ°å•ç‹¬çš„ `train.py` å’Œ `test.py` æ–‡ä»¶ã€‚\n",
        "- ç°åœ¨ï¼šæœ‰äº† `LightningModule`ï¼Œ`Trainer` è‡ªåŠ¨åŒ–äº†ä¸€åˆ‡ã€‚åªéœ€è°ƒç”¨ `trainer.fit` å’Œ `trainer.test` æ¥è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚\n",
        "- è¿‡å»ï¼šTensorFlow å–œæ¬¢ TPUï¼ŒPyTorch...å—¯ï¼\n",
        "- ç°åœ¨ï¼šä½¿ç”¨ PyTorch Lightningï¼Œå¯ä»¥è½»æ¾åœ°åœ¨å¤šä¸ª GPU ä¸Šè®­ç»ƒç›¸åŒçš„æ¨¡å‹ï¼Œç”šè‡³åœ¨ TPU ä¸Šã€‚å“‡ï¼\n",
        "- è¿‡å»ï¼šæˆ‘æ˜¯å›è°ƒçš„å¿ å®ç²‰ä¸ï¼Œæ›´å–œæ¬¢ç¼–å†™è‡ªå®šä¹‰å›è°ƒã€‚åƒ Early Stopping è¿™æ ·ç®€å•çš„äº‹æƒ…æ›¾ç»æ˜¯ä¼ ç»Ÿ PyTorch çš„è®¨è®ºç‚¹ã€‚\n",
        "- ç°åœ¨ï¼šä½¿ç”¨ PyTorch Lightningï¼Œä½¿ç”¨ Early Stopping å’Œ Model Checkpointing æ˜¯å°èœä¸€ç¢Ÿã€‚æˆ‘ç”šè‡³å¯ä»¥ç¼–å†™è‡ªå®šä¹‰å›è°ƒã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLIfDMR3JWBN"
      },
      "source": [
        "## ğŸ¨ ç»“è®ºå’Œèµ„æº\n",
        "\n",
        "æˆ‘å¸Œæœ›ä½ è§‰å¾—è¿™ä»½æŠ¥å‘Šæœ‰å¸®åŠ©ã€‚æˆ‘é¼“åŠ±ä½ ç©ä¸€ä¸‹ä»£ç ï¼Œå¹¶ä½¿ç”¨ä½ é€‰æ‹©çš„æ•°æ®é›†è®­ç»ƒä¸€ä¸ªå›¾åƒåˆ†ç±»å™¨ã€‚\n",
        "\n",
        "ä»¥ä¸‹æ˜¯ä¸€äº›å­¦ä¹ æ›´å¤šå…³äº PyTorch Lightning çš„èµ„æºï¼š\n",
        "- [é€æ­¥æ¼”ç»ƒ](https://lightning.ai/docs/pytorch/latest/starter/introduction.html) - è¿™æ˜¯å®˜æ–¹æ•™ç¨‹ä¹‹ä¸€ã€‚ä»–ä»¬çš„æ–‡æ¡£å†™å¾—éå¸¸å¥½ï¼Œæˆ‘å¼ºçƒˆæ¨èå®ƒä½œä¸ºå­¦ä¹ èµ„æºã€‚\n",
        "- [ä½¿ç”¨ PyTorch Lightning ä¸ Weights & Biases](https://wandb.me/lightning) - è¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿ colabï¼Œä½ å¯ä»¥é€šè¿‡å®ƒå­¦ä¹ å¦‚ä½•ä½¿ç”¨ W&B ä¸ PyTorch Lightningã€‚"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
